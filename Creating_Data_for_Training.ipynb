{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Creating Data for Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvdso9FMp7Ka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load, split and scale the maps dataset ready for training\n",
        "# load all images in a directory into memory\n",
        "def load_images(path, size=(256,512)):\n",
        "\tsrc_list, tar_list = list(), list()\n",
        "\t# enumerate filenames in directory, assume all are images\n",
        "\tfor filename in listdir(path):\n",
        "\t\t# load and resize the image\n",
        "\t\tpixels = load_img(path + filename, target_size=size)\n",
        "\t\t# convert to numpy array\n",
        "\t\tpixels = img_to_array(pixels)\n",
        "\t\t# split into satellite and map\n",
        "\t\tsketch_img, shoe_img = pixels[:, :256], pixels[:, 256:]\n",
        "\t\tsrc_list.append(sketch_img)\n",
        "\t\ttar_list.append(shoe_img)\n",
        "\treturn [asarray(src_list), asarray(tar_list)]\n",
        "\n",
        "# dataset path\n",
        "path = 'drive/My Drive/Train_data/'\n",
        "# load dataset\n",
        "[src_images, tar_images] = load_images(path)\n",
        "print('Loaded: ', src_images.shape, tar_images.shape)\n",
        "# save as compressed numpy array\n",
        "filename = 'shoes_256.npz'\n",
        "path2 = 'drive/My Drive/'\n",
        "savez_compressed(os.path.join(path2,filename), src_images, tar_images)\n",
        "print('Saved dataset: ', filename)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}